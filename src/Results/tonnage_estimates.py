"""
Computes tonnage estimates using predictions, CF annotations and FAO data, and generates Figure 6 ("Marine
finfish aquaculture tonnage in the French Mediterranean over time") of the manuscript
Also, estimates production within one kilometer of Trujillo et al.'s known locations.
"""

from typing import Callable, Tuple
import argparse
import geopandas as gpd
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import os
import matplotlib
import shapely
from shapely.geometry import box

from src.utils import (
    load_cf_labels, load_Trujillo_locations_deduped, load_download_bboxes, map_year_to_image_pass_opt2,
    deduplicate_download_boxes, CRS_DICT
)

# Tonnage estimates functions
from src.utils_tonnage import (
    load_production_factors, generate_period_production_factors,
    compute_facility_tonnage_estimates, load_fao_french_mediterranean, define_model_error_distributions,
    AquaFacility, load_AquaFacility, compute_complete_period_tonnage_estimates, CF_Facility,
    modify_cage_list_using_geometry
)
import src.file_utils as file_utils


def define_error_distributions(
        confidence_threshold: float,
        selected_map: Callable,
        main_dir: str
) -> Tuple[pd.DataFrame, pd.DataFrame]:
    """
    Generates the error distributions for the model predictions, and a dummy set of error distributions
    for the CF annotations (which we assume have no error).
    :param confidence_threshold: threshold used to filter out the predictions
    :param selected_map: a function mapping years to time periods
    :return: dataframe of the Normal distributions (defined by mean and std dev) for each strata (time period-cage type)
    """
    # Raw labels and predictions
    cf_labels = load_cf_labels().rename(columns={"fn": "image"})
    detections_df = gpd.read_file(f"{main_dir}/output/ocean_detections.geojson")

    download_bboxes = load_download_bboxes(os.path.join(f"{main_dir}/data/wanted_bboxes.csv"))
    dedup_boxes = deduplicate_download_boxes(
        download_bboxes, path=os.path.join(f"{main_dir}/data/wanted_bboxes_dedup.csv"))

    # Important note: this has to be the predicted df without any de-duplication, so that we can ensure we're
    # considering the exact same locations viewed by CF.
    model_error_dist = define_model_error_distributions(
        cf_labels=cf_labels, detections_df=detections_df, dedup_boxes=dedup_boxes, selected_map=selected_map,
        confidence_threshold=confidence_threshold
    )

    # Dummy error distributions (for the CF labels)
    dummy1 = pd.DataFrame({'pass': ['2019-2021', '2000-2004', '2005-2009', '2010-2012', '2013-2015', '2016-2018']})
    dummy2 = pd.DataFrame({'farm_type': ['circle_farm', 'square_farm']})
    dummy2['key'] = 0
    dummy1['key'] = 0
    model_error_dist_dummy = dummy1.merge(dummy2, how='outer')
    model_error_dist_dummy['model_error_mean'] = 0
    model_error_dist_dummy['model_error_sd'] = 0
    model_error_dist_dummy.drop('key', axis=1, inplace=True)
    return model_error_dist, model_error_dist_dummy


def compute_complete_tonnage_estimates_for_plot(
        Facility: AquaFacility,
        name: str,
        min_cage_threshold: float,
        depth_dist_mixture_param: float,
        error_distributions: pd.DataFrame,
        factor_table_distributions: pd.DataFrame,
        K=10_000) -> pd.DataFrame:
    """
    Computes the tonnage estimates, and the tonnage estimates including missing imagery adjustment for
    a given facility for each of the six time periods defined by the 'pass' variable.
    :param Facility: AquaFacility object containing the set of facilities and cages
    :param name: a str used to identify the Facility in the resulting DataFrame
    :param min_cage_threshold: Minimum cage depth
    :param depth_dist_mixture_param: Parameter for the Mixture of Truncated Normals definining the depth distribution
    :param error_distributions: dataframe of error distributions (generated by define_error_distributions) to be used
    to sample the errors in each strata
    :param factor_table_distributions: the mean and std for each time period to be used for the stocking density
    and harvest frequency
    :param K: Number of bootstrap simulations
    :return: dataframe containing the estimates (tonnage and tonnage std dev)
    """
    columns = ['source', 'pass', 'tonnage', 'tonnage_sd']

    period_estimates = compute_facility_tonnage_estimates(
        facility_df=Facility.final_facilities.copy(),
        period_factor_table=factor_table_distributions,
        period_var='pass',
        min_cage_threshold=min_cage_threshold,
        preds_df=Facility.preds.copy(),
        model_error_distributions=error_distributions,
        depth_dist_mixture_param=depth_dist_mixture_param,
        K=K
    )
    period_estimates.reset_index(inplace=True, drop=False)
    period_estimates['source'] = name
    period_estimates = period_estimates[columns]

    # Compute missing tonnage for all periods
    period_comparison_dict = {
        '2000-2004': '2005-2009',  # Use the adjacent period, which has good image coverage
        '2005-2009': '2010-2012',   # Use the next period, since period 0 has poor coverage
        '2010-2012': '2005-2009',   # Use the prior period
        '2013-2015': '2010-2012',   # Use the prior period
        '2016-2018': '2010-2012',   # Use 2010-2012, since 2013-2015 has poor coverage
        '2019-2021': '2010-2012'   # Use 2010-2012, since 2013-2015 and 2016-2018 have incomplete coverage
    }
    final_volume_estimates = pd.DataFrame()
    for current_period, compare_period in period_comparison_dict.items():
        print(current_period)
        full_period_estimates = compute_complete_period_tonnage_estimates(
            current_period=current_period, compare_period=compare_period, Facility=Facility,
            model_error_distributions=error_distributions, min_cage_threshold=min_cage_threshold,
            period_factor_table=factor_table_distributions, depth_dist_mixture_param=depth_dist_mixture_param, K=K)
        final_volume_estimates = pd.concat([final_volume_estimates, full_period_estimates])
    final_volume_estimates['source'] = f'{name} + Estimate missing'
    final_volume_estimates.reset_index(inplace=True)
    final_volume_estimates = final_volume_estimates[columns]
    final_volume_estimates.sort_values('pass', inplace=True, ascending=True)

    final_volume_estimates = pd.concat([period_estimates, final_volume_estimates])
    return final_volume_estimates


def combined_tonnage_plot(estimates: pd.DataFrame, main_dir: str) -> None:
    """
    Generates the plot with the combined Model, HITL and FAO estimates.
    @param estimates:
    @param main_dir:
    """
    x_col = 'pass'
    y_col = 'tonnage'
    lower_col = 'tonnage_sd'
    upper_col = 'tonnage_sd'
    hue_col = 'source'
    df = estimates.copy()

    u = df[x_col].unique()
    x = np.arange(len(u))
    subx = ['Model', 'FAO', 'HITL']
    offsets = (np.arange(len(subx)) - np.arange(len(subx)).mean()) / (len(subx) + 1.)
    width = np.diff(offsets).mean()

    # Model
    fig, ax = plt.subplots(figsize=(5.67, 3))
    dfg = df[(df[hue_col] == 'Model + Estimate missing')]
    ax.bar(x + offsets[0], dfg[y_col].values, width=width,
           label="Model (missing imagery)", yerr=np.stack([dfg[lower_col], dfg[upper_col]]),
           color='whitesmoke', edgecolor='steelblue', hatch='///', alpha=1,
           error_kw=dict(ecolor='steelblue', lw=1, capsize=5, capthick=0))

    dfg = df[df[hue_col] == 'Model']
    ax.bar(x + offsets[0], dfg[y_col].values, width=width,
           label="Model", yerr=np.stack([dfg[lower_col], dfg[upper_col]]), color='steelblue')

    # HITL
    dfg = df[(df[hue_col] == 'HITL + Estimate missing')]
    ax.bar(x + offsets[1], dfg[y_col].values, width=width,
           label="HITL (missing imagery)", yerr=np.stack([dfg[lower_col], dfg[upper_col]]),
           color='whitesmoke', edgecolor='mediumseagreen', hatch='///', alpha=1,
           error_kw=dict(ecolor='mediumseagreen', lw=1, capsize=5, capthick=0))

    dfg = df[df[hue_col] == 'HITL']
    ax.bar(x + offsets[1], dfg[y_col].values, width=width,
           label="HITL", yerr=np.stack([dfg[lower_col], dfg[upper_col]]), color='mediumseagreen')

    # FAO
    dfg = df[df[hue_col] == 'FAO']
    ax.bar(x + offsets[2], dfg[y_col].values, width=width,
           label="FAO statistics", yerr=np.stack([dfg[lower_col], dfg[upper_col]]), color='salmon')

    ax.set_xlabel('')
    ax.set_ylabel('Live weight - tonnes', fontname='Myriad Pro', fontsize=8)
    ax.set_xticks(x, u)
    ax.spines[['right', 'top']].set_visible(False)
    ax.legend(fontsize=8, prop={'family': 'Myriad Pro', 'size': 8})
    ax.get_yaxis().set_major_formatter(matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))

    ax.set(xlabel=None)
    ax.yaxis.label.set_size(8)
    plt.yticks(fontsize=8, fontname='Myriad Pro')
    plt.xticks(fontsize=8, fontname='Myriad Pro',)

    plt.legend(frameon=False, prop={'family': 'Myriad Pro', 'size': 8})
    plt.tight_layout()
    plt.savefig(f'{main_dir}/output/paper_figures/tonnage_estimates_combined.pdf',
                format='pdf', dpi=300, bbox_inches='tight')


def trujillo_comparison(
    Facility: AquaFacility,
    model_error_distributions: pd.DataFrame,
    factor_table_distributions: pd.DataFrame,
    min_cage_threshold: float,
    depth_dist_mixture_param: float,
    main_dir: str
) -> None:
    """
    Computes the tonnage around near known aquaculture locations.
    :param Facility: AquaFacility object containing cages
    :param model_error_distributions:
    :param factor_table_distributions:
    :param min_cage_threshold:
    :param depth_dist_mixture_param:
    :param main_dir:
    :return:
    """
    def compute_bounded_tonnage(
            Facility: AquaFacility,
            model_error_distributions: pd.DataFrame,
            bound_geom: shapely.geometry.multipolygon.MultiPolygon,
            sbound: str,
            factor_table_distributions: pd.DataFrame,
            min_cage_threshold: float,
            depth_dist_mixture_param: float,
            K=10_000
    ):
        """
        Computes tonnage inside (sbound=inside) or outside (sbound=outside) a given geometry (bound_geom).
        :param Facility: AquaFacility to be used for tonnage estimates
        :param model_error_distributions:
        :param bound_geom:
        :param sbound:
        :param factor_table_distributions:
        :param min_cage_threshold:
        :param depth_dist_mixture_param:
        :param K:
        :return:
        """
        assert sbound in ['inside', 'outside']

        bounded_facilities = Facility.final_facilities.copy()
        preds_df = Facility.preds.copy()

        # For each cage in this facility df, check it against the bounds to see if we should keep it
        for cage_id_col in ['cage_ids', 'cage_ids_max', 'cage_ids_min']:
            bounded_facilities[cage_id_col] = bounded_facilities[cage_id_col].apply(
                lambda cage_ids: modify_cage_list_using_geometry(
                    cage_ids=cage_ids, bounds=bound_geom, cage_df=preds_df, sbound=sbound))

        # Drop facilities with no cages
        bounded_facilities['length'] = bounded_facilities['cage_ids_min'].apply(lambda l: len(l))
        bounded_facilities = bounded_facilities.loc[bounded_facilities['length'] > 0]
        print(f'Number of facilities: {len(bounded_facilities)}')

        if len(bounded_facilities) == 0:
            print('[WARNING] no facilities')
            return None, None
        else:
            # Compute tonnage estimates
            estimates = compute_facility_tonnage_estimates(
                facility_df=bounded_facilities,
                period_factor_table=factor_table_distributions,
                period_var='pass',
                min_cage_threshold=min_cage_threshold,
                preds_df=preds_df,
                model_error_distributions=model_error_distributions,
                K=K,
                depth_dist_mixture_param=depth_dist_mixture_param
            )
            return bounded_facilities, estimates

    print('Loading Trujillo et al. locations.')
    jennifer_locations = load_Trujillo_locations_deduped(f"{main_dir}/data/aquaculture_med_dedupe.csv")

    # Compute 1km boxes around Trujillo facilities
    box_size = 1000
    jennifer_boxes = jennifer_locations.copy()
    jennifer_boxes.to_crs(CRS_DICT['area'], inplace=True)
    jennifer_boxes['1km_box'] = jennifer_boxes['geometry'].apply(
        lambda p: box(p.x - box_size, p.y - box_size, p.x + box_size, p.y + box_size)
    )
    jennifer_boxes.set_geometry('1km_box', inplace=True, crs=jennifer_boxes.crs)
    jennifer_boxes = jennifer_boxes[['id', '1km_box']]
    jennifer_boxes.to_crs(CRS_DICT['mapping'], inplace=True)
    jennifer_1km_bounds = jennifer_boxes['1km_box'].unary_union

    # Compute tonnage within this geometry
    jen_bounded_facilities, jen_estimates = compute_bounded_tonnage(
        Facility=Facility,
        model_error_distributions=model_error_distributions,
        bound_geom=jennifer_1km_bounds,
        sbound='inside',
        factor_table_distributions=factor_table_distributions,
        min_cage_threshold=min_cage_threshold,
        depth_dist_mixture_param=depth_dist_mixture_param,
        K=10_000
    )
    print('[INFO] Tonnage near Trujillo et al facilities for 2005-2009:')
    print(jen_estimates)

    compare_period = '2005-2009'
    jennifer_tonnage_75_France = 2008
    jennifer_tonnage_100_France = 2678
    jennifer_numcages_France = 1213

    predicted_jen_tonnage = jen_estimates.loc[compare_period]['tonnage']

    jen_bounded_facilities['num_cages'] = jen_bounded_facilities['cage_ids'].apply(lambda l: len(l))
    predicted_jen_numcages = jen_bounded_facilities.loc[jen_bounded_facilities['pass'] == compare_period][
        'num_cages'].sum()

    jennifer_combined_estimates = pd.DataFrame(
        {'Measure': ['Tonnage', 'Number of cages', 'Tonnage', 'Number of cages', 'Tonnage', 'Number of cages'],
         'Source': ['Trujillo (75%)', 'Trujillo (75%)', 'Trujillo (100%)', 'Trujillo (100%)', 'Predicted', 'Predicted'],
         'Value': [jennifer_tonnage_75_France, jennifer_numcages_France,
                   jennifer_tonnage_100_France, jennifer_numcages_France,
                   predicted_jen_tonnage, predicted_jen_numcages]})
    print(jennifer_combined_estimates)


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--conf_thresh', type=float)
    parser.add_argument('--min_cage_threshold', type=float)
    parser.add_argument('--depth_dist_mixture_param', type=float)
    args = parser.parse_args()

    root_dir = file_utils.get_root_path()
    os.makedirs(f'{root_dir}/output/paper_figures', exist_ok=True)

    tonnage_out_path = f'{root_dir}/output/paper_figures/tonnage_estimates_combined.csv'

    # Generate error distributions
    print('[INFO] Generating error distributions')
    model_error_distributions, model_error_distributions_dummy = define_error_distributions(
        confidence_threshold=args.conf_thresh, selected_map=map_year_to_image_pass_opt2, main_dir=str(root_dir))

    # Load production factor distributions
    factor_table = load_production_factors(prod_file=f"{root_dir}/data/Production Estimation Factors.xlsx")
    fao_data = load_fao_french_mediterranean(
        fao_file=f"{root_dir}/data/French_med_production_fao.csv",
        pass_map=map_year_to_image_pass_opt2)
    period_factor_table = generate_period_production_factors(
        production_factor_table=factor_table, fao_data=fao_data, period_var='pass')
    period_factor_table.rename(columns={
        'Factor Depth': 'd_mean',
        'Standard deviation Depth': 'd_sd',
        'Factor Stocking density': 's_mean',
        'Standard deviation Stocking density': 's_sd',
        'Factor Annual harvest frequency': 'h_mean',
        'Standard deviation Annual harvest frequency': 'h_sd'
    }, inplace=True)

    # FAO tonnage
    fao_tonnage_by_pass = fao_data.groupby(['year']).agg({
        'production_quantity': sum, 'pass': 'first'}).groupby('pass').agg({
        'production_quantity': [np.mean, np.std]
    })
    fao_tonnage_by_pass.columns = fao_tonnage_by_pass.columns.droplevel()
    fao_tonnage_by_pass['tonnage'] = fao_tonnage_by_pass['mean']
    fao_tonnage_by_pass['tonnage_sd'] = fao_tonnage_by_pass['std']
    fao_tonnage_by_pass.reset_index(drop=False, inplace=True)
    fao_tonnage_by_pass['source'] = 'FAO'
    fao_tonnage_by_pass = fao_tonnage_by_pass[['source', 'pass', 'tonnage', 'tonnage_sd']]

    # Load prediction facility (this is created using generate_facilities.py)
    PredictionFacility = load_AquaFacility(
        filename=f'{root_dir}/output/Facilities/AQ_tunedfacility.pkl',
        main_dir=None, selected_map=None, image_selection=None, confidence_threshold=None,
        distance_threshold=None, min_cluster_size=None, time_group=None
    )

    if not os.path.exists(tonnage_out_path):
        print('[INFO] Generating tonnage estimates for predictions')
        prediction_estimates = compute_complete_tonnage_estimates_for_plot(
            Facility=PredictionFacility, name='Model', error_distributions=model_error_distributions, K=10_000,
            min_cage_threshold=args.min_cage_threshold,
            depth_dist_mixture_param=args.depth_dist_mixture_param, factor_table_distributions=period_factor_table)

        # Load CF facility (this is created using generate_facilities.py)
        LabelFacility = load_AquaFacility(
            filename=f'{root_dir}/output/Facilities/CF_Facility.pkl', main_dir=None, selected_map=None,
            image_selection=None, confidence_threshold=None,
            distance_threshold=None, min_cluster_size=None, time_group=None
        )

        print('[INFO] Generating tonnage estimates for labels')
        label_estimates = compute_complete_tonnage_estimates_for_plot(
            Facility=LabelFacility, name='HITL', error_distributions=model_error_distributions_dummy, K=10_000,
            min_cage_threshold=args.min_cage_threshold,
            depth_dist_mixture_param=args.depth_dist_mixture_param, factor_table_distributions=period_factor_table)
        combined_estimates = pd.concat([fao_tonnage_by_pass, prediction_estimates, label_estimates])
        combined_estimates.to_csv(tonnage_out_path, index=False)
    else:
        combined_estimates = pd.read_csv(tonnage_out_path)
    # Generate plot
    print('[INFO] Generating plot')
    combined_tonnage_plot(estimates=combined_estimates, main_dir=str(root_dir))

    # Trujillo et al comparison
    trujillo_comparison(
        Facility=PredictionFacility,
        model_error_distributions=model_error_distributions,
        factor_table_distributions=period_factor_table,
        min_cage_threshold=args.min_cage_threshold,
        depth_dist_mixture_param=args.depth_dist_mixture_param,
        main_dir=str(root_dir)
    )
